# Cost configuration for LLM models used in GAIA evaluation
# Prices are in USD per 1M tokens
# Last updated: July 2025

models:
  # OpenAI Models
  gpt-4o:
    provider: "OpenAI"
    input_cost_per_1m_tokens: 2.50
    output_cost_per_1m_tokens: 10.00
    context_window: 128000
    
  gpt-4o-mini:
    provider: "OpenAI"
    input_cost_per_1m_tokens: 0.15
    output_cost_per_1m_tokens: 0.60
    context_window: 128000
    
  gpt-4-turbo:
    provider: "OpenAI"
    input_cost_per_1m_tokens: 10.00
    output_cost_per_1m_tokens: 30.00
    context_window: 128000
    
  gpt-3.5-turbo:
    provider: "OpenAI"
    input_cost_per_1m_tokens: 0.50
    output_cost_per_1m_tokens: 1.50
    context_window: 16385

  gpt-4.1:
    provider: "OpenAI"
    input_cost_per_1m_tokens: 2.00
    output_cost_per_1m_tokens: 8.00
    context_window: 1000000
    
  gpt-4.1-mini:
    provider: "OpenAI"
    input_cost_per_1m_tokens: 0.40
    output_cost_per_1m_tokens: 1.60
    context_window: 1000000
    
  gpt-4.1-nano:
    provider: "OpenAI"
    input_cost_per_1m_tokens: 0.10
    output_cost_per_1m_tokens: 0.40
    context_window: 1000000
    
  # Claude 4 Models
  claude-opus-4:
    provider: "Anthropic"
    input_cost_per_1m_tokens: 15.00
    output_cost_per_1m_tokens: 75.00
    context_window: ~200000
    
  claude-sonnet-4:
    provider: "Anthropic"
    input_cost_per_1m_tokens: 3.00
    output_cost_per_1m_tokens: 15.00
    context_window: ~200000

  # Anthropic Models
  claude-3-5-sonnet-20241022:
    provider: "Anthropic"
    input_cost_per_1m_tokens: 3.00
    output_cost_per_1m_tokens: 15.00
    context_window: 200000
    
  claude-3-haiku-20240307:
    provider: "Anthropic"
    input_cost_per_1m_tokens: 0.25
    output_cost_per_1m_tokens: 1.25
    context_window: 200000

  # Google Models
  gemini-1.5-pro:
    provider: "Google"
    input_cost_per_1m_tokens: 1.25
    output_cost_per_1m_tokens: 5.00
    context_window: 1000000
    
  gemini-1.5-flash:
    provider: "Google"
    input_cost_per_1m_tokens: 0.075
    output_cost_per_1m_tokens: 0.30
    context_window: 1000000

  # Meta Models (via Together AI)
  meta-llama/Llama-3.1-70B-Instruct-Turbo:
    provider: "Meta/Together AI"
    input_cost_per_1m_tokens: 0.88
    output_cost_per_1m_tokens: 0.88
    context_window: 128000
    
  meta-llama/Llama-3.1-8B-Instruct-Turbo:
    provider: "Meta/Together AI"
    input_cost_per_1m_tokens: 0.18
    output_cost_per_1m_tokens: 0.18
    context_window: 128000

  # DeepSeek Models
  deepseek-chat:
    provider: "DeepSeek"
    input_cost_per_1m_tokens: 0.27
    output_cost_per_1m_tokens: 1.10
    context_window: 64000

  # Alibaba Models
  qwen-plus:
    provider: "Alibaba"
    input_cost_per_1m_tokens: 0.50
    output_cost_per_1m_tokens: 1.50
    context_window: 131072

# Default model to use when specific model is not found
default_model: "gpt-4.1-nano"

# Notes:
# - Prices may vary by region and are subject to change
# - Check provider documentation for the most current pricing
# - Some providers offer volume discounts
# - Context window sizes may affect pricing for very long inputs
